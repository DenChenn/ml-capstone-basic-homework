{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Train test spilt base on folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "30\n",
      "10\n",
      "30\n",
      "10\n",
      "30\n",
      "10\n",
      "30\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "\n",
    "SMOOTH_IMAGE_PATH = \"../audio-image/smooth/\"\n",
    "ROCK_IMAGE_PATH = \"../audio-image/rock/\"\n",
    "\n",
    "filename_list = []\n",
    "label_list = []\n",
    "\n",
    "SMOOTH_LABEL = \"smooth\"\n",
    "ROCK_LABEL = \"rock\"\n",
    "\n",
    "for filename in os.listdir(SMOOTH_IMAGE_PATH):\n",
    "    if filename == \".DS_Store\":\n",
    "        continue\n",
    "    filename_list.append(filename)\n",
    "    label_list.append(SMOOTH_LABEL)\n",
    "for filename in os.listdir(ROCK_IMAGE_PATH):\n",
    "    if filename == \".DS_Store\":\n",
    "        continue\n",
    "    filename_list.append(filename)\n",
    "    label_list.append(ROCK_LABEL)\n",
    "\n",
    "# Put into dataframe for shuffle and split\n",
    "data = {\"filename\": filename_list, \"label\": label_list}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#shuffle the data and do K-fold split\n",
    "df = shuffle(df)\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "split_index = 0\n",
    "\n",
    "os.mkdir(\"../dataset/\")\n",
    "TRAIN_PATH = \"train/\"\n",
    "VAL_PATH = \"val/\"\n",
    "TRAIN_SMOOTH_PATH = \"train/smooth/\"\n",
    "TRAIN_ROCK_PATH = \"train/rock/\"\n",
    "VAL_SMOOTH_PATH = \"val/smooth/\"\n",
    "VAL_ROCK_PATH = \"val/rock/\"\n",
    "\n",
    "for train_index, val_index in kf.split(df):\n",
    "    split_index += 1\n",
    "    SPLIT_FOLDER_PATH = \"../dataset/K\" + str(split_index) + \"/\"\n",
    "\n",
    "    os.mkdir(SPLIT_FOLDER_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + TRAIN_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + TRAIN_SMOOTH_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + TRAIN_ROCK_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + VAL_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + VAL_SMOOTH_PATH)\n",
    "    os.mkdir(SPLIT_FOLDER_PATH + VAL_ROCK_PATH)\n",
    "\n",
    "    train_set = df.iloc[train_index]\n",
    "    val_set = df.iloc[val_index]\n",
    "\n",
    "    for i in train_set.index:\n",
    "        fn = train_set[\"filename\"][i]\n",
    "        if train_set[\"label\"][i] == SMOOTH_LABEL:\n",
    "            shutil.copyfile(SMOOTH_IMAGE_PATH + fn, SPLIT_FOLDER_PATH + TRAIN_SMOOTH_PATH + fn)\n",
    "        else:\n",
    "            shutil.copyfile(ROCK_IMAGE_PATH + fn, SPLIT_FOLDER_PATH + TRAIN_ROCK_PATH + fn)\n",
    "\n",
    "    for i in val_set.index:\n",
    "        fn = val_set[\"filename\"][i]\n",
    "        if val_set[\"label\"][i] == SMOOTH_LABEL:\n",
    "            shutil.copyfile(SMOOTH_IMAGE_PATH + fn, SPLIT_FOLDER_PATH + VAL_SMOOTH_PATH + fn)\n",
    "        else:\n",
    "            shutil.copyfile(ROCK_IMAGE_PATH + fn, SPLIT_FOLDER_PATH + VAL_ROCK_PATH + fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Put into dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define some constants\n",
    "INPUT_WIDTH = 128\n",
    "INPUT_HEIGHT = 128\n",
    "NUM_OF_SPLIT = 4\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Define container\n",
    "train_dataloader_list = []\n",
    "val_dataloader_list = []\n",
    "\n",
    "# define custom transform\n",
    "resize_transform = transforms.Resize(size=(INPUT_HEIGHT, INPUT_WIDTH))\n",
    "\n",
    "# mix transform for\n",
    "custom_transform = transforms.Compose([resize_transform, transforms.ToTensor()])\n",
    "\n",
    "for i in range(NUM_OF_SPLIT):\n",
    "    index = i + 1\n",
    "    TRAIN_ROOT_PATH = \"../dataset/K\" +  str(index) + \"/train/\"\n",
    "    VAL_ROOT_PATH = \"../dataset/K\" + str(index) + \"/val/\"\n",
    "\n",
    "    train_dataset = ImageFolder(root=TRAIN_ROOT_PATH, transform=custom_transform)\n",
    "    val_dataset = ImageFolder(root=VAL_ROOT_PATH, transform=custom_transform)\n",
    "\n",
    "    train_dataloader_list.append(DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False))\n",
    "    val_dataloader_list.append(DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define CNN model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # In the init function, we define each layer we will use in our model\n",
    "\n",
    "        # Our images are RGB, so we have input channels = 3.\n",
    "        # We will apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # We in the end apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # This means that our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "\n",
    "        # We need to flatten these in order to feed them to a fully-connected layer\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In the forward function, pass the data through the layers we defined in the init function\n",
    "\n",
    "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "\n",
    "        # Use a ReLU activation function after layer 2\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        # Return class probabilities via a log_softmax function\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "k1_cnn = CNNModel()\n",
    "k2_cnn = CNNModel()\n",
    "k3_cnn = CNNModel()\n",
    "k4_cnn = CNNModel()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss function and optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "k1_optimizer = optim.SGD(k1_cnn.parameters(), lr=0.0001, momentum=0.9)\n",
    "k2_optimizer = optim.SGD(k2_cnn.parameters(), lr=0.0001, momentum=0.9)\n",
    "k3_optimizer = optim.SGD(k3_cnn.parameters(), lr=0.0001, momentum=0.9)\n",
    "k4_optimizer = optim.SGD(k4_cnn.parameters(), lr=0.0001, momentum=0.9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training model and print result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 30.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 70.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 30.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 30.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 30.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 30.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 50.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 70.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 70.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 40.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 80.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 70.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 90.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K1 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K2 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K3 in one epoch\n",
      "Accuracy: 100.0 %\n",
      "Finish training K4 in one epoch\n"
     ]
    }
   ],
   "source": [
    "def train_model(cnn_model, optimizer, criterion_func,  train_dataloader, val_dataloader, model_name):\n",
    "    for index, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = criterion_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #print(f'epoch: {epoch + 1}, iteration: {i + 1}, loss: {loss.item()}')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in val_dataloader:\n",
    "            images, labels = d\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = cnn_model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy: {100 * correct / total} %')\n",
    "\n",
    "    print(\"Finish training \" + model_name + \" in one epoch\")\n",
    "\n",
    "num_of_epoch = 20\n",
    "for epoch in range(num_of_epoch):  # loop over the dataset multiple times\n",
    "    train_model(k1_cnn, k1_optimizer, criterion, train_dataloader_list[0], val_dataloader_list[0], \"K1\")\n",
    "    train_model(k2_cnn, k2_optimizer, criterion, train_dataloader_list[1], val_dataloader_list[1], \"K2\")\n",
    "    train_model(k3_cnn, k3_optimizer, criterion, train_dataloader_list[2], val_dataloader_list[2], \"K3\")\n",
    "    train_model(k4_cnn, k4_optimizer, criterion, train_dataloader_list[3], val_dataloader_list[3], \"K4\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis and result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0, 0.0], [0.0, 5.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "def get_result(cnn_model, val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        pred = []\n",
    "        ans = []\n",
    "        for d in val_dataloader:\n",
    "            images, labels = d\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = cnn_model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred.append(predicted.item())\n",
    "            ans.append(labels.item())\n",
    "\n",
    "    return pred, ans\n",
    "\n",
    "\n",
    "predict = [] # An 2D array storing 4 models predictions\n",
    "answer = [] # An 2D array storing 4 models' validation correct answers\n",
    "\n",
    "p, a = get_result(k1_cnn, val_dataloader_list[0])\n",
    "predict.append(p)\n",
    "answer.append(a)\n",
    "p, a = get_result(k2_cnn, val_dataloader_list[1])\n",
    "predict.append(p)\n",
    "answer.append(a)\n",
    "p, a = get_result(k3_cnn, val_dataloader_list[2])\n",
    "predict.append(p)\n",
    "answer.append(a)\n",
    "p, a = get_result(k4_cnn, val_dataloader_list[3])\n",
    "predict.append(p)\n",
    "answer.append(a)\n",
    "\n",
    "# get average of confusion matrix\n",
    "confusion_matrix_list = []\n",
    "for i in range(len(predict)):\n",
    "    confusion_matrix_list.append(confusion_matrix(answer[i], predict[i]))\n",
    "\n",
    "\n",
    "result_confusion_matrix = [[0, 0], [0, 0]]\n",
    "for c in confusion_matrix_list:\n",
    "    for row in range(len(c)):\n",
    "        for col in range(len(c[row])):\n",
    "            result_confusion_matrix[row][col] += c[row][col]\n",
    "\n",
    "for row in range(len(result_confusion_matrix)):\n",
    "    for col in range(len(result_confusion_matrix[row])):\n",
    "        result_confusion_matrix[row][col] = result_confusion_matrix[row][col] / 4.0\n",
    "\n",
    "print(result_confusion_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      "Average accuracy score: 1.0\n",
      "Average recall score: 1.0\n",
      "Average precision score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# get average accuracy, recall and precision\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "\n",
    "for i in range(len(predict)):\n",
    "    accuracy_list.append(accuracy_score(answer[i], predict[i]))\n",
    "    recall_list.append(recall_score(answer[i], predict[i]))\n",
    "    precision_list.append(precision_score(answer[i], predict[i]))\n",
    "\n",
    "print(accuracy_list)\n",
    "print(recall_list)\n",
    "print(precision_list)\n",
    "\n",
    "print(\"Average accuracy score: \" + str(sum(accuracy_list) / 4))\n",
    "print(\"Average recall score: \" + str(sum(recall_list) / 4))\n",
    "print(\"Average precision score: \" + str(sum(precision_list) / 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}